{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "colab": {
      "name": "spacy.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gladiator07/Natural-Language-Processing/blob/main/Basics/Text-Preprocessing/spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvjWN2EYH9-_"
      },
      "source": [
        "# Spacy Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5l_Odg1IDoT"
      },
      "source": [
        "### References\n",
        "- [Overview of Spacy](https://www.analyticsvidhya.com/blog/2020/03/spacy-tutorial-learn-natural-language-processing/)\n",
        "- [Comprehensive article](https://www.machinelearningplus.com/spacy-tutorial-nlp/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "913dxs1GIZb8"
      },
      "source": [
        "## Spacy's Processing Pipeline\n",
        "\n",
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/spacy_pipeline.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwrbuGIEIh-2"
      },
      "source": [
        "The first step for a text string, when working with spaCy, is to pass it to an NLP object. This object is essentially a pipeline of several text pre-processing operations through which the input text string has to go through."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5PMzW-AIhWP"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErlyuvqTH9_B"
      },
      "source": [
        "# create an nlp object\n",
        "doc = nlp(\"He went to play basketball\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3i2-63RIvus",
        "outputId": "8c68d2ad-9bdf-463f-a5ae-6b944e05a1b4"
      },
      "source": [
        "# seeing the active pipelines\n",
        "nlp.pipe_names"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tagger', 'parser', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S6ipj6LI0cM",
        "outputId": "3cecbdb9-1d35-4491-b476-8f9100411d4d"
      },
      "source": [
        "# disable pipeline components (if not required, can save up the computation)\n",
        "nlp.disable_pipes('tagger', 'parser')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7fe7259c9690>),\n",
              " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7fe721bb2520>)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7OzXq-7I_G8",
        "outputId": "ea7aa0dd-5aeb-4950-bc89-8730581b75b0"
      },
      "source": [
        "nlp.pipe_names"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ner']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vcWtbYuJHbU"
      },
      "source": [
        "## 1.POS Tagging (Part-of-Speech)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O0r-vBMJMfL"
      },
      "source": [
        "In English grammar, the parts of speech tell us what is the function of a word and how it is used in a sentence. Some of the common parts of speech in English are Noun, Pronoun, Adjective, Verb, Adverb, etc.\n",
        "\n",
        "POS tagging is the task of automatically assigning POS tags to all the words of a sentence. It is helpful in various downstream tasks in NLP, such as feature engineering, language understanding, and information extraction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQO3RZ4nJAmc",
        "outputId": "4099492c-5e08-4794-d84d-5166b7415ee2"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# create an nlp object\n",
        "doc = nlp(\"He went to play basketball\")\n",
        "\n",
        "# iterate over the tokens\n",
        "for token in doc:\n",
        "    print(token.text, \"-->\", token.pos_)\n",
        "    # print(token)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He --> PRON\n",
            "went --> VERB\n",
            "to --> PART\n",
            "play --> VERB\n",
            "basketball --> NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qlI0GNJXJgxs",
        "outputId": "5ff94337-fcf8-43c1-b2f3-eac3c31631ef"
      },
      "source": [
        "# if not sure what the POS tag does, you can use the explain method\n",
        "spacy.explain(\"PART\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'particle'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYQfdXvmKFR_"
      },
      "source": [
        "## 2. Dependency Parsing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjDWalsZKKf8"
      },
      "source": [
        "Every sentence has a grammatical structure to it and with the help of dependency parsing, we can extract this structure. It can also be thought of as a directed graph, where nodes correspond to the words in the sentence and the edges between the nodes are the corresponding dependencies between the word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdjMka0pJ5Q8",
        "outputId": "7183c04a-7ba1-4320-9419-c8cc0c8e968e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for token in doc:\n",
        "    print(token.text, \"-->\", token.dep_)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He --> nsubj\n",
            "went --> ROOT\n",
            "to --> aux\n",
            "play --> advcl\n",
            "basketball --> dobj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azB8ccdVK0ti",
        "outputId": "0a1751a4-d23d-4102-b173-5c8fce4cbcf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for token in doc:\n",
        "    print(token.dep_, \"-->\",spacy.explain(token.dep_))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nsubj --> nominal subject\n",
            "ROOT --> None\n",
            "aux --> auxiliary\n",
            "advcl --> adverbial clause modifier\n",
            "dobj --> direct object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma4Dn7KrLXBF"
      },
      "source": [
        "### 3.Named Entity Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiSXHSZELdPF"
      },
      "source": [
        " Entities are the words or groups of words that represent information about common things such as persons, locations, organizations, etc. These entities have proper names.\n",
        "\n",
        "For example, consider the following sentence:\n",
        "\n",
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/sentence.png)\n",
        "\n",
        "In this sentence, the entities are “Donald Trump”, “Google”, and “New York City”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zOJfP8IK_Up",
        "outputId": "8c863360-d8e4-4446-a87a-a007882913ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc = nlp(\"Indians spent over $71 billion on clothes in 2018\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, \"-->\", ent.label_)\n",
        "    print(ent.label_, \"-->\", spacy.explain(ent))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indians --> NORP\n",
            "NORP --> None\n",
            "$71 billion --> MONEY\n",
            "MONEY --> None\n",
            "2018 --> DATE\n",
            "DATE --> None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGIXykPLMRGl"
      },
      "source": [
        "### 4. Rule-Based Matching using Spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkCAatX-N97K"
      },
      "source": [
        "Rule-based matching is a new addition to spaCy’s arsenal. With this spaCy matcher, you can find words and phrases in the text using user-defined rules.\n",
        "\n",
        "`It is like Regular Expressions on steroids.`\n",
        "\n",
        "While Regular Expressions use text patterns to find words and phrases, the spaCy matcher not only uses the text patterns but lexical properties of the word, such as POS tags, dependency tags, lemma, etc.\n",
        "\n",
        "Let’s see how it works:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8zjkKK_Lq0J"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# initialize the mathcer with spacy vocabulary\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "doc = nlp(\"Some people start their day with lemon water\")\n",
        "\n",
        "# define rule\n",
        "pattern = [{'TEXT': 'lemon'}, {'TEXT' : 'water'}]\n",
        "\n",
        "# add rule\n",
        "matcher.add('rule_1', None, pattern)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nKLWylYOrvH"
      },
      "source": [
        "So, our objective is that whenever “lemon” is followed by the word “water”, then the matcher should be able to find this pattern in the text. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu-GsLEkOh1o",
        "outputId": "aafaddc8-5e78-4821-d64c-14d8823bf91f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "matches = matcher(doc)\n",
        "matches"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(7604275899133490726, 6, 8)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2N7tvpEOy32"
      },
      "source": [
        "The output has three elements. The first element, ‘7604275899133490726’, is the match ID. The second and third elements are the positions of the matched tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sERmlI53OvUY",
        "outputId": "623c31f5-1a71-40fd-8689-a0cbf2a80455",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for match_id, start, end in matches:\n",
        "    matched_span = doc[start:end]\n",
        "    print(matched_span.text)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemon water\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr3pAW35PCqi"
      },
      "source": [
        "So, the pattern is a list of token attributes. For example, ‘TEXT’ is a token attribute that means the exact text of the token. There are, in fact, many other useful token attributes in spaCy which can be used to define a variety of rules and patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI_EPteOPHRz"
      },
      "source": [
        "For more rules visit : https://spacy.io/usage/rule-based-matching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "090CX90tPVWx"
      },
      "source": [
        "Let’s see another use case of the spaCy matcher. Consider the two sentences below:\n",
        "\n",
        "- You can read this book\n",
        "- I will book my ticket\n",
        "\n",
        "Now we are interested in finding whether a sentence contains the word “book” in it or not. It seems pretty straight forward right? But here is the catch – we have to find the word “book” only if it has been used in the sentence as a noun.\n",
        "\n",
        "In the first sentence above, “book” has been used as a noun and in the second sentence, it has been used as a verb. So, the spaCy matcher should be able to extract the pattern from the first sentence only. Let’s try it out:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-bOqj8cO6H_"
      },
      "source": [
        "doc1 = nlp(\"You read this book\")\n",
        "doc2 = nlp(\"I will book my ticket\")\n",
        "\n",
        "pattern = [{'TEXT': 'book', 'POS': 'NOUN'}]\n",
        "\n",
        "# Initialize the matcher with the shared vocab\n",
        "matcher = Matcher(nlp.vocab)\n",
        "matcher.add('rule_2', None, pattern)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoDJ4TfPPZ00",
        "outputId": "6603e1ba-f3df-4544-fc10-15202f54081b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "matches = matcher(doc1)\n",
        "matches"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(375134486054924901, 3, 4)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2-7YiApPf0a"
      },
      "source": [
        "The matcher has found the pattern in the first sentence.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBU0LwJSPcLO",
        "outputId": "4861c08a-ce39-485c-99c3-a716c8a160cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "matches = matcher(doc2)\n",
        "matches"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVuYP3x_PiwW"
      },
      "source": [
        "Nice! Though “book” is present in the second sentence, the matcher ignored it as it was not a noun."
      ]
    }
  ]
}